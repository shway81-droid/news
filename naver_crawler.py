"""ë„¤ì´ë²„ ë‰´ìŠ¤ í—¤ë“œë¼ì¸ í¬ë¡¤ëŸ¬"""
import requests
from bs4 import BeautifulSoup
from typing import List, Dict, Tuple


# ë„¤ì´ë²„ ì–¸ë¡ ì‚¬ ì½”ë“œ ë§¤í•‘
PRESS_CODES = {
    # ê²½ì œ ì‹ ë¬¸
    '015': 'í•œêµ­ê²½ì œ',
    '009': 'ë§¤ì¼ê²½ì œ',
    '011': 'ì„œìš¸ê²½ì œ',
    '008': 'ë¨¸ë‹ˆíˆ¬ë°ì´',
    '014': 'íŒŒì´ë‚¸ì…œë‰´ìŠ¤',
    # ì£¼ìš” ì¼ê°„ì§€
    '023': 'ì¡°ì„ ì¼ë³´',
    '025': 'ì¤‘ì•™ì¼ë³´',
    '020': 'ë™ì•„ì¼ë³´',
    '028': 'í•œê²¨ë ˆ',
    '032': 'ê²½í–¥ì‹ ë¬¸',
    # ê¸°íƒ€ ì°¸ê³ ìš©
    '001': 'ì—°í•©ë‰´ìŠ¤',
    '030': 'ì „ìì‹ ë¬¸',
    '081': 'ì„œìš¸ì‹ ë¬¸',
    '088': 'ë§¤ì¼ì‹ ë¬¸',
    '005': 'êµ­ë¯¼ì¼ë³´',
}

# ìˆ˜ì§‘ ëŒ€ìƒ ì–¸ë¡ ì‚¬ ì½”ë“œ
TARGET_ECONOMY = ['015', '009', '011', '008', '014']  # í•œê²½, ë§¤ê²½, ì„œìš¸ê²½ì œ, ë¨¸ë‹ˆíˆ¬ë°ì´, íŒŒì´ë‚¸ì…œ
TARGET_DAILY = ['023', '025', '020', '028', '032']    # ì¡°ì¤‘ë™, í•œê²¨ë ˆ, ê²½í–¥


def fetch_naver_headlines() -> Tuple[List[Dict], List[Dict]]:
    """ë„¤ì´ë²„ ë‰´ìŠ¤ ë©”ì¸ì—ì„œ ì–¸ë¡ ì‚¬ë³„ í—¤ë“œë¼ì¸ ìˆ˜ì§‘

    Returns:
        (ê²½ì œ ë‰´ìŠ¤ ë¦¬ìŠ¤íŠ¸, ì¼ê°„ì§€ ë‰´ìŠ¤ ë¦¬ìŠ¤íŠ¸)
    """
    url = 'https://news.naver.com'
    headers = {
        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36'
    }

    try:
        response = requests.get(url, headers=headers, timeout=15)
        response.raise_for_status()
    except Exception as e:
        print(f"âŒ ë„¤ì´ë²„ ë‰´ìŠ¤ ì ‘ì† ì‹¤íŒ¨: {e}")
        return [], []

    soup = BeautifulSoup(response.text, 'html.parser')
    headlines = soup.select('a[class*="headline"]')

    # ì–¸ë¡ ì‚¬ë³„ ì²« ê¸°ì‚¬ ìˆ˜ì§‘ (ì¤‘ë³µ ë°©ì§€)
    economy_news = {}
    daily_news = {}

    for item in headlines:
        title = item.get_text(strip=True).replace('ì‹ ë¬¸ë³´ê¸°', '').strip()
        href = item.get('href', '')

        # URLì—ì„œ ì–¸ë¡ ì‚¬ ì½”ë“œ ì¶”ì¶œ
        if 'press/' not in href:
            continue

        press_code = href.split('press/')[1].split('/')[0]
        press_name = PRESS_CODES.get(press_code, f'ì–¸ë¡ ì‚¬({press_code})')

        news_item = {
            'title': title,
            'source': press_name,
            'link': href,
            'press_code': press_code
        }

        # ê²½ì œ ì‹ ë¬¸ (ì•„ì§ ìˆ˜ì§‘ ì•ˆ ëœ ì–¸ë¡ ì‚¬ë§Œ)
        if press_code in TARGET_ECONOMY and press_code not in economy_news:
            economy_news[press_code] = news_item

        # ì¼ê°„ì§€ (ì•„ì§ ìˆ˜ì§‘ ì•ˆ ëœ ì–¸ë¡ ì‚¬ë§Œ)
        if press_code in TARGET_DAILY and press_code not in daily_news:
            daily_news[press_code] = news_item

    # dictë¥¼ listë¡œ ë³€í™˜
    economy_list = list(economy_news.values())
    daily_list = list(daily_news.values())

    return economy_list, daily_list


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    print("=== ë„¤ì´ë²„ ë‰´ìŠ¤ í—¤ë“œë¼ì¸ í¬ë¡¤ë§ í…ŒìŠ¤íŠ¸ ===\n")

    economy, daily = fetch_naver_headlines()

    print("ğŸ’° ê²½ì œ ì‹ ë¬¸ í—¤ë“œë¼ì¸:")
    for news in economy:
        print(f"  âœ… {news['source']}: {news['title'][:50]}...")
    print(f"  â†’ {len(economy)}/5ê°œ ìˆ˜ì§‘\n")

    print("ğŸ“° ì£¼ìš” ì¼ê°„ì§€ í—¤ë“œë¼ì¸:")
    for news in daily:
        print(f"  âœ… {news['source']}: {news['title'][:50]}...")
    print(f"  â†’ {len(daily)}/5ê°œ ìˆ˜ì§‘")
